{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c00cee2-613e-47fc-8251-dade062461f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "956a7e6b-510a-4591-bf81-096292bdd11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 数据预处理\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# 设置数据集路径\n",
    "data_path = './cifar-10'  # 确保这是正确的路径\n",
    "\n",
    "# 加载本地数据集\n",
    "train_dataset = datasets.CIFAR10(root=data_path, train=True, download=False, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root=data_path, train=False, download=False, transform=transform)\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b063dd61-76c5-4b7e-a8a5-b554b01f787d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_dataloader = train_loader\n",
    "test_dataloader = test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b416003-8f98-4fea-b8de-264774382ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchcp.classification.scores import THR\n",
    "from torchcp.classification.predictors import SplitPredictor\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        # 计算卷积层输出的尺寸\n",
    "        self.fc1_input_size = self._calculate_conv_output_size()\n",
    "        self.fc1 = nn.Linear(self.fc1_input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def _calculate_conv_output_size(self):\n",
    "        # 假设输入尺寸是 32x32\n",
    "        size = 32\n",
    "        # 通过两次卷积和池化操作\n",
    "        size = (size - 2) // 2  # 第一次卷积和池化\n",
    "        size = (size - 2) // 2  # 第二次卷积和池化\n",
    "        # 返回展平后的尺寸\n",
    "        return size * size * 64  # 64 是最后一个卷积层的输出通道数\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f218befb-aea6-4a74-a1fb-83a52ecbe0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/50000 (0%)]\tLoss: 2.296635\n",
      "Train Epoch: 0 [6400/50000 (13%)]\tLoss: 2.275448\n",
      "Train Epoch: 0 [12800/50000 (26%)]\tLoss: 2.231324\n",
      "Train Epoch: 0 [19200/50000 (38%)]\tLoss: 2.099237\n",
      "Train Epoch: 0 [25600/50000 (51%)]\tLoss: 2.189346\n",
      "Train Epoch: 0 [32000/50000 (64%)]\tLoss: 2.048845\n",
      "Train Epoch: 0 [38400/50000 (77%)]\tLoss: 1.860424\n",
      "Train Epoch: 0 [44800/50000 (90%)]\tLoss: 1.904531\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 1.830040\n",
      "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 2.024997\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 1.816044\n",
      "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 1.697010\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.762069\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 1.815694\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 1.738655\n",
      "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 1.741190\n"
     ]
    }
   ],
   "source": [
    "# 实例化模型\n",
    "model = SimpleCNN()\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# 模型训练\n",
    "model.train()\n",
    "for epoch in range(2):  # 多次循环遍历数据集\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07f5bdfc-56e0-4e6e-a50d-7268a3a86a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将模型设为评估模式\n",
    "model.eval()\n",
    "\n",
    "# 定义一个TorchCP预测器\n",
    "predictor = SplitPredictor(score_function=THR(), model=model)\n",
    "\n",
    "# 使用训练数据的一部分进行校准\n",
    "predictor.calibrate(train_loader, alpha=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03130a1f-3b93-469f-a7ea-5e1f1c987438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SplitPredictor THR 覆盖率: 0.8986 平均集合大小: 4.6245\n",
      "SplitPredictor APS 覆盖率: 0.8964 平均集合大小: 4.8175\n",
      "SplitPredictor SAPS 覆盖率: 0.8975 平均集合大小: 5.0044\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "RAPS.__init__() missing 1 required positional argument: 'penalty'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 50\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSplitPredictor SAPS 覆盖率:\u001b[39m\u001b[38;5;124m\"\u001b[39m, result_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCoverage_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m平均集合大小:\u001b[39m\u001b[38;5;124m\"\u001b[39m, result_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage_size\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# # 或者使用RAPS得分\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m predictor \u001b[38;5;241m=\u001b[39m SplitPredictor(score_function\u001b[38;5;241m=\u001b[39m\u001b[43mRAPS\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m     51\u001b[0m predictor\u001b[38;5;241m.\u001b[39mcalibrate(train_loader, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# 预测测试数据集的实例\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# 注意：这里我们使用 DataLoader 提供的数据进行预测\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: RAPS.__init__() missing 1 required positional argument: 'penalty'"
     ]
    }
   ],
   "source": [
    "# 将模型设为评估模式\n",
    "from torchcp.classification.predictors import ClusterPredictor, ClassWisePredictor\n",
    "from torchcp.classification.scores import APS, SAPS, RAPS\n",
    "model.eval()\n",
    "weight_value = 0.5\n",
    "penalty = 0.5\n",
    "# 定义一个TorchCP预测器\n",
    "predictor = SplitPredictor(score_function=THR(), model=model)\n",
    "# 使用训练数据的一部分进行校准\n",
    "predictor.calibrate(train_loader, alpha=0.1)\n",
    "# 预测测试数据集的实例\n",
    "# 注意：这里我们使用 DataLoader 提供的数据进行预测\n",
    "for data, _ in test_loader:\n",
    "    predict_sets = predictor.predict(data)\n",
    "    # print(predict_sets)\n",
    "    break  # 此处仅展示一个批次的预测结果\n",
    "\n",
    "# 评估覆盖率和平均集合大小\n",
    "result_dict = predictor.evaluate(test_loader)\n",
    "print(\"SplitPredictor THR 覆盖率:\", result_dict[\"Coverage_rate\"], \"平均集合大小:\", result_dict[\"Average_size\"])\n",
    "\n",
    "# 使用APS得分\n",
    "predictor = SplitPredictor(score_function=APS(), model=model)\n",
    "predictor.calibrate(train_loader, alpha=0.1)\n",
    "# 预测测试数据集的实例\n",
    "# 注意：这里我们使用 DataLoader 提供的数据进行预测\n",
    "for data, _ in test_loader:\n",
    "    predict_sets = predictor.predict(data)\n",
    "    # print(predict_sets)\n",
    "    break  # 此处仅展示一个批次的预测结果\n",
    "\n",
    "# 评估覆盖率和平均集合大小\n",
    "result_dict = predictor.evaluate(test_loader)\n",
    "print(\"SplitPredictor APS 覆盖率:\", result_dict[\"Coverage_rate\"], \"平均集合大小:\", result_dict[\"Average_size\"])\n",
    "\n",
    "\n",
    "# # 或者使用SAPS得分\n",
    "predictor = SplitPredictor(score_function=SAPS(weight=weight_value), model=model)\n",
    "predictor.calibrate(train_loader, alpha=0.1)\n",
    "# 预测测试数据集的实例\n",
    "# 注意：这里我们使用 DataLoader 提供的数据进行预测\n",
    "for data, _ in test_loader:\n",
    "    predict_sets = predictor.predict(data)\n",
    "    # print(predict_sets)\n",
    "    break  # 此处仅展示一个批次的预测结果\n",
    "\n",
    "# 评估覆盖率和平均集合大小\n",
    "result_dict = predictor.evaluate(test_loader)\n",
    "print(\"SplitPredictor SAPS 覆盖率:\", result_dict[\"Coverage_rate\"], \"平均集合大小:\", result_dict[\"Average_size\"])\n",
    "# # 或者使用RAPS得分\n",
    "predictor = SplitPredictor(score_function=RAPS(penalty=penalty_value), model=model)\n",
    "predictor.calibrate(train_loader, alpha=0.1)\n",
    "# 预测测试数据集的实例\n",
    "# 注意：这里我们使用 DataLoader 提供的数据进行预测\n",
    "for data, _ in test_loader:\n",
    "    predict_sets = predictor.predict(data)\n",
    "    # print(predict_sets)\n",
    "    break  # 此处仅展示一个批次的预测结果\n",
    "\n",
    "# 评估覆盖率和平均集合大小\n",
    "result_dict = predictor.evaluate(test_loader)\n",
    "print(\"SplitPredictor RAPS 覆盖率:\", result_dict[\"Coverage_rate\"], \"平均集合大小:\", result_dict[\"Average_size\"])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # 使用ClusterPredictor\n",
    "# predictor = ClusterPredictor(score_function=THR(), model=model)\n",
    "\n",
    "# 定义一个TorchCP预测器\n",
    "predictor = ClusterPredictor(score_function=THR(), model=model)\n",
    "# 使用训练数据的一部分进行校准\n",
    "predictor.calibrate(train_loader, alpha=0.1)\n",
    "# 预测测试数据集的实例\n",
    "# 注意：这里我们使用 DataLoader 提供的数据进行预测\n",
    "for data, _ in test_loader:\n",
    "    predict_sets = predictor.predict(data)\n",
    "    # print(predict_sets)\n",
    "    break  # 此处仅展示一个批次的预测结果\n",
    "\n",
    "# 评估覆盖率和平均集合大小\n",
    "result_dict = predictor.evaluate(test_loader)\n",
    "print(\"ClusterPredictor THR 覆盖率:\", result_dict[\"Coverage_rate\"], \"平均集合大小:\", result_dict[\"Average_size\"])\n",
    "\n",
    "# 使用APS得分\n",
    "predictor = ClusterPredictor(score_function=APS(), model=model)\n",
    "predictor.calibrate(train_loader, alpha=0.1)\n",
    "# 预测测试数据集的实例\n",
    "# 注意：这里我们使用 DataLoader 提供的数据进行预测\n",
    "for data, _ in test_loader:\n",
    "    predict_sets = predictor.predict(data)\n",
    "    # print(predict_sets)\n",
    "    break  # 此处仅展示一个批次的预测结果\n",
    "\n",
    "# 评估覆盖率和平均集合大小\n",
    "result_dict = predictor.evaluate(test_loader)\n",
    "print(\"ClusterPredictor APS 覆盖率:\", result_dict[\"Coverage_rate\"], \"平均集合大小:\", result_dict[\"Average_size\"])\n",
    "\n",
    "\n",
    "# # 或者使用SAPS得分\n",
    "predictor = ClusterPredictor(score_function=SAPS(weight=weight_value), model=model)\n",
    "predictor.calibrate(train_loader, alpha=0.1)\n",
    "# 预测测试数据集的实例\n",
    "# 注意：这里我们使用 DataLoader 提供的数据进行预测\n",
    "for data, _ in test_loader:\n",
    "    predict_sets = predictor.predict(data)\n",
    "    # print(predict_sets)\n",
    "    break  # 此处仅展示一个批次的预测结果\n",
    "\n",
    "# 评估覆盖率和平均集合大小\n",
    "result_dict = predictor.evaluate(test_loader)\n",
    "print(\"ClusterPredictor SAPS 覆盖率:\", result_dict[\"Coverage_rate\"], \"平均集合大小:\", result_dict[\"Average_size\"])\n",
    "# # 或者使用RAPS得分\n",
    "predictor = ClusterPredictor(score_function=RAPS(penalty=penalty_value), model=model)\n",
    "predictor.calibrate(train_loader, alpha=0.1)\n",
    "# 预测测试数据集的实例\n",
    "# 注意：这里我们使用 DataLoader 提供的数据进行预测\n",
    "for data, _ in test_loader:\n",
    "    predict_sets = predictor.predict(data)\n",
    "    # print(predict_sets)\n",
    "    break  # 此处仅展示一个批次的预测结果\n",
    "\n",
    "# 评估覆盖率和平均集合大小\n",
    "result_dict = predictor.evaluate(test_loader)\n",
    "print(\"ClusterPredictor RAPS 覆盖率:\", result_dict[\"Coverage_rate\"], \"平均集合大小:\", result_dict[\"Average_size\"])\n",
    "\n",
    "# # 或者使用ClassWisePredictor\n",
    "# predictor = ClassWisePredictor(score_function=THR(), model=model)\n",
    "\n",
    "# 定义一个TorchCP预测器\n",
    "predictor = ClassWisePredictor(score_function=THR(), model=model)\n",
    "# 使用训练数据的一部分进行校准\n",
    "predictor.calibrate(train_loader, alpha=0.1)\n",
    "# 预测测试数据集的实例\n",
    "# 注意：这里我们使用 DataLoader 提供的数据进行预测\n",
    "for data, _ in test_loader:\n",
    "    predict_sets = predictor.predict(data)\n",
    "    # print(predict_sets)\n",
    "    break  # 此处仅展示一个批次的预测结果\n",
    "\n",
    "# 评估覆盖率和平均集合大小\n",
    "result_dict = predictor.evaluate(test_loader)\n",
    "print(\"ClassWisePredictor THR 覆盖率:\", result_dict[\"Coverage_rate\"], \"平均集合大小:\", result_dict[\"Average_size\"])\n",
    "\n",
    "# 使用APS得分\n",
    "predictor = ClassWisePredictor(score_function=APS(), model=model)\n",
    "predictor.calibrate(train_loader, alpha=0.1)\n",
    "# 预测测试数据集的实例\n",
    "# 注意：这里我们使用 DataLoader 提供的数据进行预测\n",
    "for data, _ in test_loader:\n",
    "    predict_sets = predictor.predict(data)\n",
    "    # print(predict_sets)\n",
    "    break  # 此处仅展示一个批次的预测结果\n",
    "\n",
    "# 评估覆盖率和平均集合大小\n",
    "result_dict = predictor.evaluate(test_loader)\n",
    "print(\"ClassWisePredictor APS 覆盖率:\", result_dict[\"Coverage_rate\"], \"平均集合大小:\", result_dict[\"Average_size\"])\n",
    "\n",
    "\n",
    "# # 或者使用SAPS得分\n",
    "predictor = ClassWisePredictor(score_function=SAPS(weight=weight_value), model=model)\n",
    "predictor.calibrate(train_loader, alpha=0.1)\n",
    "# 预测测试数据集的实例\n",
    "# 注意：这里我们使用 DataLoader 提供的数据进行预测\n",
    "for data, _ in test_loader:\n",
    "    predict_sets = predictor.predict(data)\n",
    "    # print(predict_sets)\n",
    "    break  # 此处仅展示一个批次的预测结果\n",
    "\n",
    "# 评估覆盖率和平均集合大小\n",
    "result_dict = predictor.evaluate(test_loader)\n",
    "print(\"ClassWisePredictor SAPS 覆盖率:\", result_dict[\"Coverage_rate\"], \"平均集合大小:\", result_dict[\"Average_size\"])\n",
    "# # 或者使用RAPS得分\n",
    "predictor = ClassWisePredictor(score_function=RAPS(penalty=penalty_value), model=model)\n",
    "predictor.calibrate(train_loader, alpha=0.1)\n",
    "# 预测测试数据集的实例\n",
    "# 注意：这里我们使用 DataLoader 提供的数据进行预测\n",
    "for data, _ in test_loader:\n",
    "    predict_sets = predictor.predict(data)\n",
    "    # print(predict_sets)\n",
    "    break  # 此处仅展示一个批次的预测结果\n",
    "\n",
    "# 评估覆盖率和平均集合大小\n",
    "result_dict = predictor.evaluate(test_loader)\n",
    "print(\"ClassWisePredictor RAPS 覆盖率:\", result_dict[\"Coverage_rate\"], \"平均集合大小:\", result_dict[\"Average_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ca331b1-bf05-4c4d-a2bd-1839a62ea81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SplitPredictor RAPS 覆盖率: 0.896 平均集合大小: 5.0526\n",
      "ClusterPredictor THR 覆盖率: 0.899 平均集合大小: 4.6314\n",
      "ClusterPredictor APS 覆盖率: 0.8983 平均集合大小: 4.813\n",
      "ClusterPredictor SAPS 覆盖率: 0.8962 平均集合大小: 5.0035\n",
      "ClusterPredictor RAPS 覆盖率: 0.8969 平均集合大小: 5.0596\n",
      "ClassWisePredictor THR 覆盖率: 0.8972 平均集合大小: 4.5816\n",
      "ClassWisePredictor APS 覆盖率: 0.8953 平均集合大小: 4.8074\n",
      "ClassWisePredictor SAPS 覆盖率: 0.8975 平均集合大小: 4.9645\n",
      "ClassWisePredictor RAPS 覆盖率: 0.8962 平均集合大小: 4.9332\n"
     ]
    }
   ],
   "source": [
    "# 将模型设为评估模式\n",
    "from torchcp.classification.predictors import ClusterPredictor, ClassWisePredictor\n",
    "from torchcp.classification.scores import APS, SAPS, RAPS\n",
    "model.eval()\n",
    "weight_value = 0.5\n",
    "penalty_value = 0.5\n",
    "\n",
    "# # 或者使用RAPS得分\n",
    "predictor = SplitPredictor(score_function=RAPS(penalty=penalty_value), model=model)\n",
    "predictor.calibrate(train_loader, alpha=0.1)\n",
    "# 预测测试数据集的实例\n",
    "# 注意：这里我们使用 DataLoader 提供的数据进行预测\n",
    "for data, _ in test_loader:\n",
    "    predict_sets = predictor.predict(data)\n",
    "    # print(predict_sets)\n",
    "    break  # 此处仅展示一个批次的预测结果\n",
    "\n",
    "# 评估覆盖率和平均集合大小\n",
    "result_dict = predictor.evaluate(test_loader)\n",
    "print(\"SplitPredictor RAPS 覆盖率:\", result_dict[\"Coverage_rate\"], \"平均集合大小:\", result_dict[\"Average_size\"])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # 使用ClusterPredictor\n",
    "# predictor = ClusterPredictor(score_function=THR(), model=model)\n",
    "\n",
    "# 定义一个TorchCP预测器\n",
    "predictor = ClusterPredictor(score_function=THR(), model=model)\n",
    "# 使用训练数据的一部分进行校准\n",
    "predictor.calibrate(train_loader, alpha=0.1)\n",
    "# 预测测试数据集的实例\n",
    "# 注意：这里我们使用 DataLoader 提供的数据进行预测\n",
    "for data, _ in test_loader:\n",
    "    predict_sets = predictor.predict(data)\n",
    "    # print(predict_sets)\n",
    "    break  # 此处仅展示一个批次的预测结果\n",
    "\n",
    "# 评估覆盖率和平均集合大小\n",
    "result_dict = predictor.evaluate(test_loader)\n",
    "print(\"ClusterPredictor THR 覆盖率:\", result_dict[\"Coverage_rate\"], \"平均集合大小:\", result_dict[\"Average_size\"])\n",
    "\n",
    "# 使用APS得分\n",
    "predictor = ClusterPredictor(score_function=APS(), model=model)\n",
    "predictor.calibrate(train_loader, alpha=0.1)\n",
    "# 预测测试数据集的实例\n",
    "# 注意：这里我们使用 DataLoader 提供的数据进行预测\n",
    "for data, _ in test_loader:\n",
    "    predict_sets = predictor.predict(data)\n",
    "    # print(predict_sets)\n",
    "    break  # 此处仅展示一个批次的预测结果\n",
    "\n",
    "# 评估覆盖率和平均集合大小\n",
    "result_dict = predictor.evaluate(test_loader)\n",
    "print(\"ClusterPredictor APS 覆盖率:\", result_dict[\"Coverage_rate\"], \"平均集合大小:\", result_dict[\"Average_size\"])\n",
    "\n",
    "\n",
    "# # 或者使用SAPS得分\n",
    "predictor = ClusterPredictor(score_function=SAPS(weight=weight_value), model=model)\n",
    "predictor.calibrate(train_loader, alpha=0.1)\n",
    "# 预测测试数据集的实例\n",
    "# 注意：这里我们使用 DataLoader 提供的数据进行预测\n",
    "for data, _ in test_loader:\n",
    "    predict_sets = predictor.predict(data)\n",
    "    # print(predict_sets)\n",
    "    break  # 此处仅展示一个批次的预测结果\n",
    "\n",
    "# 评估覆盖率和平均集合大小\n",
    "result_dict = predictor.evaluate(test_loader)\n",
    "print(\"ClusterPredictor SAPS 覆盖率:\", result_dict[\"Coverage_rate\"], \"平均集合大小:\", result_dict[\"Average_size\"])\n",
    "# # 或者使用RAPS得分\n",
    "predictor = ClusterPredictor(score_function=RAPS(penalty=penalty_value), model=model)\n",
    "predictor.calibrate(train_loader, alpha=0.1)\n",
    "# 预测测试数据集的实例\n",
    "# 注意：这里我们使用 DataLoader 提供的数据进行预测\n",
    "for data, _ in test_loader:\n",
    "    predict_sets = predictor.predict(data)\n",
    "    # print(predict_sets)\n",
    "    break  # 此处仅展示一个批次的预测结果\n",
    "\n",
    "# 评估覆盖率和平均集合大小\n",
    "result_dict = predictor.evaluate(test_loader)\n",
    "print(\"ClusterPredictor RAPS 覆盖率:\", result_dict[\"Coverage_rate\"], \"平均集合大小:\", result_dict[\"Average_size\"])\n",
    "\n",
    "# # 或者使用ClassWisePredictor\n",
    "# predictor = ClassWisePredictor(score_function=THR(), model=model)\n",
    "\n",
    "# 定义一个TorchCP预测器\n",
    "predictor = ClassWisePredictor(score_function=THR(), model=model)\n",
    "# 使用训练数据的一部分进行校准\n",
    "predictor.calibrate(train_loader, alpha=0.1)\n",
    "# 预测测试数据集的实例\n",
    "# 注意：这里我们使用 DataLoader 提供的数据进行预测\n",
    "for data, _ in test_loader:\n",
    "    predict_sets = predictor.predict(data)\n",
    "    # print(predict_sets)\n",
    "    break  # 此处仅展示一个批次的预测结果\n",
    "\n",
    "# 评估覆盖率和平均集合大小\n",
    "result_dict = predictor.evaluate(test_loader)\n",
    "print(\"ClassWisePredictor THR 覆盖率:\", result_dict[\"Coverage_rate\"], \"平均集合大小:\", result_dict[\"Average_size\"])\n",
    "\n",
    "# 使用APS得分\n",
    "predictor = ClassWisePredictor(score_function=APS(), model=model)\n",
    "predictor.calibrate(train_loader, alpha=0.1)\n",
    "# 预测测试数据集的实例\n",
    "# 注意：这里我们使用 DataLoader 提供的数据进行预测\n",
    "for data, _ in test_loader:\n",
    "    predict_sets = predictor.predict(data)\n",
    "    # print(predict_sets)\n",
    "    break  # 此处仅展示一个批次的预测结果\n",
    "\n",
    "# 评估覆盖率和平均集合大小\n",
    "result_dict = predictor.evaluate(test_loader)\n",
    "print(\"ClassWisePredictor APS 覆盖率:\", result_dict[\"Coverage_rate\"], \"平均集合大小:\", result_dict[\"Average_size\"])\n",
    "\n",
    "\n",
    "# # 或者使用SAPS得分\n",
    "predictor = ClassWisePredictor(score_function=SAPS(weight=weight_value), model=model)\n",
    "predictor.calibrate(train_loader, alpha=0.1)\n",
    "# 预测测试数据集的实例\n",
    "# 注意：这里我们使用 DataLoader 提供的数据进行预测\n",
    "for data, _ in test_loader:\n",
    "    predict_sets = predictor.predict(data)\n",
    "    # print(predict_sets)\n",
    "    break  # 此处仅展示一个批次的预测结果\n",
    "\n",
    "# 评估覆盖率和平均集合大小\n",
    "result_dict = predictor.evaluate(test_loader)\n",
    "print(\"ClassWisePredictor SAPS 覆盖率:\", result_dict[\"Coverage_rate\"], \"平均集合大小:\", result_dict[\"Average_size\"])\n",
    "# # 或者使用RAPS得分\n",
    "predictor = ClassWisePredictor(score_function=RAPS(penalty=penalty_value), model=model)\n",
    "predictor.calibrate(train_loader, alpha=0.1)\n",
    "# 预测测试数据集的实例\n",
    "# 注意：这里我们使用 DataLoader 提供的数据进行预测\n",
    "for data, _ in test_loader:\n",
    "    predict_sets = predictor.predict(data)\n",
    "    # print(predict_sets)\n",
    "    break  # 此处仅展示一个批次的预测结果\n",
    "\n",
    "# 评估覆盖率和平均集合大小\n",
    "result_dict = predictor.evaluate(test_loader)\n",
    "print(\"ClassWisePredictor RAPS 覆盖率:\", result_dict[\"Coverage_rate\"], \"平均集合大小:\", result_dict[\"Average_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7910df-30ff-4f58-8500-d47b13276408",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tutorial-env",
   "language": "python",
   "name": "tutorial-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
